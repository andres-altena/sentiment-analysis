{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andres\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:40: UserWarning: h5py is running against HDF5 1.10.5 when it was built against 1.10.4, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "#A bit hacky but we aren't planning on using keras on GPU so we disable warnings \n",
    "#(otherwise Jupyter crashes)\n",
    "os.environ['HDF5_DISABLE_VERSION_CHECK']='1'\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import *\n",
    "import pandas as pd\n",
    "#Import tagged data\n",
    "path_to_tagged = Path(\"..\") / \"data\" / \"processed\" / \"tagged_data.xlsx\"\n",
    "tagged_df = pd.read_excel(path_to_tagged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore data\n",
    "\n",
    "#We have not tagged all the messages (too many) so lets have a look at only the tagged ones:\n",
    "tagged_df.dropna(axis=0, inplace = True)\n",
    "tagged_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the data is tagged 1-5 for sad (1) to happy (5) we have to convert this to a binary for now\n",
    "def make_binary(num):\n",
    "    if num > 3:\n",
    "        return \"Positive\"\n",
    "    elif num < 3:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "    \n",
    "tagged_df[\"Binary\"] = [make_binary(x) for x in tagged_df[\"1 to 5\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positve messages: 176\n",
      "Number of neutral messages: 207\n",
      "Number of negative messages: 134\n"
     ]
    }
   ],
   "source": [
    "#We want to keep the number of positive negative and neutral messages ~ equal for training\n",
    "print(\"Number of positve messages:\", sum(tagged_df[\"Binary\"] ==  \"Positive\"))\n",
    "print(\"Number of neutral messages:\", sum(tagged_df[\"Binary\"] ==  \"Neutral\"))\n",
    "print(\"Number of negative messages:\", sum(tagged_df[\"Binary\"] ==  \"Negative\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>IsGroup</th>\n",
       "      <th>StillPart</th>\n",
       "      <th>NumParticipants</th>\n",
       "      <th>Participants</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Message</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>type</th>\n",
       "      <th>Preprocessed</th>\n",
       "      <th>1 to 5</th>\n",
       "      <th>Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abandonment Issues but like fr this time</td>\n",
       "      <td>RegularGroup</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>Shail Desai,Eleanor King,Preben Monteiro Ness,...</td>\n",
       "      <td>Andres Altena</td>\n",
       "      <td>Plenty of alcohol in Benetd bte</td>\n",
       "      <td>2019-06-26 21:22:33.740</td>\n",
       "      <td>Generic</td>\n",
       "      <td>['plenty', 'of', 'alcohol', 'in', 'benetd', 'b...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abandonment Issues but like fr this time</td>\n",
       "      <td>RegularGroup</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>Shail Desai,Eleanor King,Preben Monteiro Ness,...</td>\n",
       "      <td>Andres Altena</td>\n",
       "      <td>But I'm free already</td>\n",
       "      <td>2019-06-26 20:55:31.858</td>\n",
       "      <td>Generic</td>\n",
       "      <td>['but', 'free', 'already']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abandonment Issues but like fr this time</td>\n",
       "      <td>RegularGroup</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>Shail Desai,Eleanor King,Preben Monteiro Ness,...</td>\n",
       "      <td>Andres Altena</td>\n",
       "      <td>Ye it is</td>\n",
       "      <td>2019-06-26 20:55:20.553</td>\n",
       "      <td>Generic</td>\n",
       "      <td>['ye', 'it', 'is']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abandonment Issues but like fr this time</td>\n",
       "      <td>RegularGroup</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>Shail Desai,Eleanor King,Preben Monteiro Ness,...</td>\n",
       "      <td>Andres Altena</td>\n",
       "      <td>Anyone still around?</td>\n",
       "      <td>2019-06-26 20:50:43.524</td>\n",
       "      <td>Generic</td>\n",
       "      <td>['anyone', 'still', 'around']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abandonment Issues but like fr this time</td>\n",
       "      <td>RegularGroup</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>Shail Desai,Eleanor King,Preben Monteiro Ness,...</td>\n",
       "      <td>Andres Altena</td>\n",
       "      <td>I'm ready for this party</td>\n",
       "      <td>2019-06-26 20:50:36.682</td>\n",
       "      <td>Generic</td>\n",
       "      <td>['ready', 'for', 'this', 'party']</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>Pals</td>\n",
       "      <td>RegularGroup</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>Andres Altena,Lauren Rodney,Anya Davidson</td>\n",
       "      <td>Andres Altena</td>\n",
       "      <td>What are these</td>\n",
       "      <td>2020-11-12 10:56:13.356</td>\n",
       "      <td>Generic</td>\n",
       "      <td>['what', 'are', 'these']</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>Pals</td>\n",
       "      <td>RegularGroup</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>Andres Altena,Lauren Rodney,Anya Davidson</td>\n",
       "      <td>Andres Altena</td>\n",
       "      <td>We good</td>\n",
       "      <td>2020-11-12 10:56:06.042</td>\n",
       "      <td>Generic</td>\n",
       "      <td>['we', 'good']</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Pals</td>\n",
       "      <td>RegularGroup</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>Andres Altena,Lauren Rodney,Anya Davidson</td>\n",
       "      <td>Andres Altena</td>\n",
       "      <td>Today is the last day</td>\n",
       "      <td>2020-11-12 10:56:00.275</td>\n",
       "      <td>Generic</td>\n",
       "      <td>['today', 'is', 'the', 'last', 'day']</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Pals</td>\n",
       "      <td>RegularGroup</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>Andres Altena,Lauren Rodney,Anya Davidson</td>\n",
       "      <td>Andres Altena</td>\n",
       "      <td>I'm full on having an existential crisis while...</td>\n",
       "      <td>2020-11-12 10:54:23.594</td>\n",
       "      <td>Generic</td>\n",
       "      <td>['full', 'on', 'having', 'an', 'existential', ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Pals</td>\n",
       "      <td>RegularGroup</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>Andres Altena,Lauren Rodney,Anya Davidson</td>\n",
       "      <td>Andres Altena</td>\n",
       "      <td>Yeah it really does</td>\n",
       "      <td>2020-11-12 10:53:49.832</td>\n",
       "      <td>Generic</td>\n",
       "      <td>['yeah', 'it', 'really', 'does']</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title       IsGroup  StillPart  \\\n",
       "0    Abandonment Issues but like fr this time  RegularGroup      False   \n",
       "1    Abandonment Issues but like fr this time  RegularGroup      False   \n",
       "2    Abandonment Issues but like fr this time  RegularGroup      False   \n",
       "3    Abandonment Issues but like fr this time  RegularGroup      False   \n",
       "4    Abandonment Issues but like fr this time  RegularGroup      False   \n",
       "..                                        ...           ...        ...   \n",
       "512                                      Pals  RegularGroup       True   \n",
       "513                                      Pals  RegularGroup       True   \n",
       "514                                      Pals  RegularGroup       True   \n",
       "515                                      Pals  RegularGroup       True   \n",
       "516                                      Pals  RegularGroup       True   \n",
       "\n",
       "     NumParticipants                                       Participants  \\\n",
       "0                  9  Shail Desai,Eleanor King,Preben Monteiro Ness,...   \n",
       "1                  9  Shail Desai,Eleanor King,Preben Monteiro Ness,...   \n",
       "2                  9  Shail Desai,Eleanor King,Preben Monteiro Ness,...   \n",
       "3                  9  Shail Desai,Eleanor King,Preben Monteiro Ness,...   \n",
       "4                  9  Shail Desai,Eleanor King,Preben Monteiro Ness,...   \n",
       "..               ...                                                ...   \n",
       "512                3          Andres Altena,Lauren Rodney,Anya Davidson   \n",
       "513                3          Andres Altena,Lauren Rodney,Anya Davidson   \n",
       "514                3          Andres Altena,Lauren Rodney,Anya Davidson   \n",
       "515                3          Andres Altena,Lauren Rodney,Anya Davidson   \n",
       "516                3          Andres Altena,Lauren Rodney,Anya Davidson   \n",
       "\n",
       "            Sender                                            Message  \\\n",
       "0    Andres Altena                    Plenty of alcohol in Benetd bte   \n",
       "1    Andres Altena                               But I'm free already   \n",
       "2    Andres Altena                                           Ye it is   \n",
       "3    Andres Altena                               Anyone still around?   \n",
       "4    Andres Altena                           I'm ready for this party   \n",
       "..             ...                                                ...   \n",
       "512  Andres Altena                                     What are these   \n",
       "513  Andres Altena                                            We good   \n",
       "514  Andres Altena                              Today is the last day   \n",
       "515  Andres Altena  I'm full on having an existential crisis while...   \n",
       "516  Andres Altena                                Yeah it really does   \n",
       "\n",
       "                    DateTime     type  \\\n",
       "0    2019-06-26 21:22:33.740  Generic   \n",
       "1    2019-06-26 20:55:31.858  Generic   \n",
       "2    2019-06-26 20:55:20.553  Generic   \n",
       "3    2019-06-26 20:50:43.524  Generic   \n",
       "4    2019-06-26 20:50:36.682  Generic   \n",
       "..                       ...      ...   \n",
       "512  2020-11-12 10:56:13.356  Generic   \n",
       "513  2020-11-12 10:56:06.042  Generic   \n",
       "514  2020-11-12 10:56:00.275  Generic   \n",
       "515  2020-11-12 10:54:23.594  Generic   \n",
       "516  2020-11-12 10:53:49.832  Generic   \n",
       "\n",
       "                                          Preprocessed  1 to 5    Binary  \n",
       "0    ['plenty', 'of', 'alcohol', 'in', 'benetd', 'b...     4.0  Positive  \n",
       "1                           ['but', 'free', 'already']     4.0  Positive  \n",
       "2                                   ['ye', 'it', 'is']     4.0  Positive  \n",
       "3                        ['anyone', 'still', 'around']     4.0  Positive  \n",
       "4                    ['ready', 'for', 'this', 'party']     5.0  Positive  \n",
       "..                                                 ...     ...       ...  \n",
       "512                           ['what', 'are', 'these']     3.0   Neutral  \n",
       "513                                     ['we', 'good']     3.0   Neutral  \n",
       "514              ['today', 'is', 'the', 'last', 'day']     3.0   Neutral  \n",
       "515  ['full', 'on', 'having', 'an', 'existential', ...     2.0  Negative  \n",
       "516                   ['yeah', 'it', 'really', 'does']     3.0   Neutral  \n",
       "\n",
       "[517 rows x 12 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-3-14c34c81624f>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-14c34c81624f>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    tokenizer.fit_on_texts(#andres_df[\"Message\"])\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#Initialise tokenizer, this will be used to produce bag of words etc\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(#andres_df[\"Message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Found: <class 'tensorflow.python.keras.layers.embeddings.Embedding'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3e4f56bf4ab3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"sigmoid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    182\u001b[0m       raise TypeError('The added layer must be '\n\u001b[0;32m    183\u001b[0m                       \u001b[1;34m'an instance of class Layer. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                       'Found: ' + str(layer))\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: <class 'tensorflow.python.keras.layers.embeddings.Embedding'>"
     ]
    }
   ],
   "source": [
    "#Initialise model\n",
    "model = Sequential()\n",
    "\n",
    "#need to feed embedding total layer number of words\n",
    "num_words = ???\n",
    "model.add(Embedding(num_words, 32))\n",
    "model.add(LSTM(32, dropout = 0.1, recurrent_dropout = 0))\n",
    "model.add(Dense(32, activation = \"relu\"))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile - set parameters ie loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters for training - early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
